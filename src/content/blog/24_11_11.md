---
title: 'AWS-SAA 문제풀이'
description: 'AWS SAA-C03 자격증 문제풀이'
pubDate: '2024.11.11'
---

**회사에서는 Amazon DynamoDB 테이블을 사용하는 애플리케이션에 대한 테스트를
수행합니다. 테스트는 일주일에 한 번 4 시간 동안 진행됩니다. 회사는 테스트 중에
애플리케이션이 매초 테이블에 대해 수행하는 읽기 및 쓰기 작업 수를 알고 있습니다.
회사는 현재 다른 사용 사례에 DynamoDB 를 사용하지 않습니다. 솔루션 설계자는 테이블
비용을 최적화해야 합니다.
어떤 솔루션이 이러한 요구 사항을 충족합니까?**

<div class="options">

A. 주문형 모드를 선택하세요. 읽기 및 쓰기 용량 단위를 적절하게 업데이트합니다.

B. 프로비저닝 모드를 선택합니다. 읽기 및 쓰기 용량 단위를 적절하게 업데이트합니다.

C. 1 년 기간 동안 DynamoDB 예약 용량을 구매합니다.

D. 3 년 기간 동안 DynamoDB 예약 용량을 구매하세요.</div>

<details class="markdown-toggle">
  <summary><b>Answer</b></summary>
  <div markdown="1">
    <ul>
      <li>
        <span class="answer">B</span> <br/>
      </li>
    </ul>
    
- **A**: 주문형(on-demand) 모드는 **간헐적인 사용에 맞는 유연성**을 제공하지만, 프로비저닝 모드에 비해 **장시간에 걸쳐 트래픽이 예측 가능한 상황에서는 더 비싸질 수 있음**.

- **C, D**: **예약 용량**은 꾸준한 사용이 예상될 때 비용 절감에 유리하지만, **테스트가 일주일에 4시간으로 짧게 이루어지는 상황**에서는 오히려 불필요한 비용을 초래할 수 있음.
  </div>
</details>

---

---

**회사는 Amazon EC2 인스턴스에서 애플리케이션을 실행합니다. 회사는 AWS 비용에 대해
정기적인 재무 평가를 수행합니다. 회사는 최근 비정상적인 지출을 확인했습니다. 회사는
비정상적인 지출을 방지하기 위한 솔루션이 필요합니다. 솔루션은 비용을 모니터링하고
비정상적인 지출이 발생할 경우 책임 있는 이해관계자에게 알려야 합니다.
어떤 솔루션이 이러한 요구 사항을 충족합니까?**

<div class="options">

A. 지출이 없는 예산을 생성하려면 AWS Budgets 템플릿을 사용하십시오.

B. AWS Billing and Cost Management 콘솔에서 AWS 비용 이상 탐지 모니터를 생성합니다.

C. 현재 실행 중인 워크로드 가격 세부 정보에 대한 AWS 가격 계산기 추정치를
생성합니다.

D. Amazon CloudWatch 를 사용하여 비용을 모니터링하고 비정상적인 지출을 식별합니다.A. 지출이 없는 예산을 생성하려면 AWS Budgets 템플릿을 사용하십시오.

B. AWS Billing and Cost Management 콘솔에서 AWS 비용 이상 탐지 모니터를 생성합니다.

C. 현재 실행 중인 워크로드 가격 세부 정보에 대한 AWS 가격 계산기 추정치를
생성합니다.

D. Amazon CloudWatch 를 사용하여 비용을 모니터링하고 비정상적인 지출을 식별합니다.</div>

<details class="markdown-toggle">
  <summary><b>Answer</b></summary>
  <div markdown="1">
    <ul>
      <li>
        <span class="answer">B</span> <br/>
      </li>
    </ul>
  
- AWS Billing and Cost Management의 **비용 이상 탐지 기능**은 사용 패턴을 분석하여 **비정상적인 비용 증가를 자동으로 감지하고 알림을 보낼 수 있음**. 이는 예산을 초과하거나 예상치 못한 지출이 발생할 때 신속하게 책임자에게 알리는 데 적합한 솔루션임.

    - **A**: AWS Budgets를 통해 **예산을 설정하고 초과 시 알림**을 보낼 수는 있지만, 이는 **사전 정의된 예산을 초과할 때만 경고**함. 비정상 지출을 실시간으로 감지하는 데는 적합하지 않음.

    - **C**: AWS 가격 계산기는 **사용 예상 비용을 사전에 계산**하는 데 도움이 되며, 실시간 모니터링 및 이상 탐지 기능은 없음.
    - **D**: Amazon CloudWatch는 **애플리케이션 및 인프라의 성능을 모니터링**하는 도구로, 비용 이상 감지 및 경고 기능이 없음.

  </div>
</details>

---

---

**마케팅 회사는 마케팅 캠페인을 통해 Amazon S3 에서 대량의 새로운 클릭스트림 데이터를
받습니다. 회사는 Amazon S3의 클릭스트림 데이터를 신속하게 분석해야 합니다. 그런 다음
회사는 데이터 파이프라인에서 데이터를 추가로 처리할지 여부를 결정해야 합니다.
최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?**

<div class="options">

A. Spark 카탈로그에 외부 테이블을 생성합니다. 데이터를 쿼리하도록 AWS Glue 에서
작업을 구성합니다.

B. 데이터를 크롤링하도록 AWS Glue 크롤러를 구성합니다. 데이터를 쿼리하도록 Amazon
Athena 를 구성합니다.

C. Hive 메타스토어에 외부 테이블을 생성합니다. 데이터를 쿼리하도록 Amazon EMR 에서
Spark 작업을 구성합니다.

D. 데이터를 크롤링하도록 AWS Glue 크롤러를 구성합니다. SQL 을 사용하여 데이터를
쿼리하도록 Amazon Kinesis Data Analytics 를 구성합니다.</div>

<details class="markdown-toggle">
  <summary><b>Answer</b></summary>
  <div markdown="1">
    <ul>
      <li>
        <span class="answer">B</span> <br/>
      </li>
    </ul>
    
   **AWS Glue 크롤러**: Glue 크롤러는 S3에 저장된 다양한 데이터 소스의 **스키마를 자동으로 탐지**하여 Glue 데이터 카탈로그에 저장함. 이를 통해 S3 데이터를 Athena와 같은 서비스에서 쉽게 조회할 수 있도록 지원함.

**Amazon Athena**: Athena는 S3에 저장된 데이터를 **SQL 쿼리**로 분석할 수 있는 서버리스 서비스임. Glue 데이터 카탈로그와 연동해 자동으로 데이터를 인식하고, 이를 통해 분석할 수 있음. 운영 오버헤드가 적고 빠른 데이터 조회가 가능해 빠르게 결과를 확인하고 추가 처리 여부를 결정하는 데 적합함.

- **A**: AWS Glue 작업과 Spark를 통한 쿼리는 가능하지만, 초기 데이터 탐지에는 Glue 크롤러와 Athena의 결합이 더 간편하고 운영 오버헤드가 적음.

- **C**: Hive 메타스토어 및 EMR 사용은 복잡한 데이터 처리에 적합하지만, 초기 데이터 탐지 및 쿼리 작업에 대한 오버헤드가 큼.
- **D**: Amazon Kinesis Data Analytics는 **실시간 데이터 분석에 적합**하나, Amazon S3에 저장된 데이터를 SQL 쿼리로 신속하게 분석하는 데는 적합하지 않음.

  </div>
</details>

---

---

**한 회사는 데이터 센터에서 SMB 파일 서버를 운영하고 있습니다. 파일서버는 회사가 자주
접속하는 대용량 파일을 파일 생성일로부터 최대 7일까지 저장합니다. 7일이 지나면 회사는
최대 24 시간의 검색 시간으로 파일에 액세스할 수 있어야 합니다.
어떤 솔루션이 이러한 요구 사항을 충족합니까?**

<div class="options">

A. AWS DataSync 를 사용하여 SMB 파일 서버에서 AWS 로 7 일보다 오래된 데이터를
복사합니다.

B. 회사의 저장 공간을 늘리려면 Amazon S3 파일 게이트웨이를 생성하십시오. 7 일 후에
데이터를 S3 Glacier Deep Archive 로 전환하는 S3 수명 주기 정책을 생성합니다.

C. 회사의 저장 공간을 늘리기 위해 Amazon FSx 파일 게이트웨이를 생성합니다. 7 일 후에
데이터를 전환하는 Amazon S3 수명 주기 정책을 생성합니다.

D. 각 사용자에 대해 Amazon S3 에 대한 액세스를 구성합니다. 7 일 후에 데이터를 S3
Glacier 유연한 검색으로 전환하는 S3 수명 주기 정책을 생성합니다.</div>

<details class="markdown-toggle">
  <summary><b>Answer</b></summary>
  <div markdown="1">
    <ul>
      <li>
        <span class="answer">B</span> <br/>
      </li>
    </ul>
    
- **Amazon S3 파일 게이트웨이**는 온프레미스 애플리케이션이 **SMB 프로토콜**을 통해 Amazon S3에 저장된 파일에 접근할 수 있게 함. 이를 통해 데이터 센터에서 자주 접속하는 파일을 S3에 저장할 수 있음. S3 **수명 주기 정책**을 설정하여 파일이 생성된 지 7일이 지나면 S3 Glacier Deep Archive로 전환 가능함. Deep Archive는 매우 저렴한 저장 비용을 제공하며, 최대 24시간의 검색 시간 옵션을 제공해 7일 이후에도 요구 사항을 충족할 수 있음.

    - **A**: AWS DataSync는 SMB 파일 서버의 데이터를 AWS로 복사하는 데 적합하나, DataSync 자체로 수명 주기 관리를 지원하지 않아 추가 설정이 필요함.

    - **C**: Amazon FSx 파일 게이트웨이는 S3와의 직접적인 연결을 제공하지 않음. 대신 Windows 파일 서버 환경을 온프레미스에서 AWS로 확장하려는 경우에 유용함.

    - **D**: Amazon S3에 개별 사용자별 액세스를 설정하는 것은 불필요하게 복잡함. 파일 게이트웨이를 통한 중앙 관리가 효율적임.

  </div>
</details>

---

---

**한 회사가 Auto Scaling 그룹의 Amazon EC2 인스턴스에서 웹 애플리케이션을 실행합니다.
애플리케이션은 PostgreSQL DB 인스턴스용 Amazon RDS 에서 실행되는 데이터베이스를
사용합니다. 트래픽이 증가하면 애플리케이션 성능이 느려집니다. 트래픽이 많은 기간 동안
데이터베이스에 읽기 로드가 많이 발생합니다.
이러한 성능 문제를 해결하기 위해 솔루션 설계자는 어떤 조치를 취해야 합니까? (2 개
선택)**

<div class="options">

A. DB 인스턴스에 대해 Auto Scaling 을 활성화합니다.

B. DB 인스턴스에 대한 읽기 전용 복제본을 생성합니다. 읽기 트래픽을 읽기 전용
복제본으로 보내도록 애플리케이션을 구성합니다.

C. DB 인스턴스를 다중 AZ DB 인스턴스 배포로 변환합니다. 대기 DB 인스턴스에 읽기
트래픽을 보내도록 애플리케이션을 구성합니다.

D. Amazon ElastiCache 클러스터를 생성합니다. ElastiCache 클러스터에서 쿼리 결과를
캐시하도록 애플리케이션을 구성합니다.

E. EC2 인스턴스가 DB 인스턴스와 동일한 가용 영역에 프로비저닝되도록 Auto Scaling
그룹 서브넷을 구성합니다.</div>

<details class="markdown-toggle">
  <summary><b>Answer</b></summary>
  <div markdown="1">
    <ul>
      <li>
        <span class="answer">B,D</span> <br/>
      </li>
    </ul>
    
- **B.** 읽기 전용 복제본(Read Replica)을 사용하면 트래픽이 많은 시기에 데이터베이스의 읽기 부하를 줄일 수 있음. 읽기 전용 복제본을 생성하고 애플리케이션에서 읽기 요청을 복제본으로 분산하면 메인 DB 인스턴스의 부하가 줄어들어 성능이 향상됨.

- **D.** Amazon ElastiCache는 자주 사용하는 데이터의 캐시를 유지하여 DB 요청 수를 줄일 수 있음. 캐시된 데이터를 사용함으로써, 데이터베이스에 대한 직접적인 읽기 요청 수가 줄어 성능이 향상됨. 이는 특히 빈번하게 사용되는 쿼리에 대해 유용함.

  - **A**: Amazon RDS DB 인스턴스는 EC2와 같은 방식의 Auto Scaling 기능을 지원하지 않음.
  - **C**: 다중 AZ 배포는 주로 데이터베이스의 고가용성을 제공하기 위한 것이므로, 성능 최적화에는 크게 도움이 되지 않음.
  - **E**: EC2 인스턴스와 DB 인스턴스가 동일한 가용 영역에 위치하는 것은 지연 시간을 줄일 수 있지만, 근본적인 읽기 부하 문제 해결에는 큰 도움이 되지 않음.

    </div>
  </details>

---

---

**회사는 Amazon EC2 인스턴스와 Amazon Elastic Block Store(Amazon EBS) 볼륨을
사용하여 애플리케이션을 실행합니다. 회사는 규정 준수 요구 사항을 충족하기 위해 매일
각 EBS 볼륨에 대해 하나의 스냅샷을 생성합니다. 회사는 EBS 볼륨 스냅샷이 실수로
삭제되는 것을 방지하는 아키텍처를 구현하려고 합니다. 솔루션은 스토리지 관리자
사용자의 관리 권한을 변경해서는 안 됩니다.
최소한의 관리 노력으로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?**

<div class="options">

A. 스냅샷 삭제 권한이 있는 IAM 역할을 생성합니다. 새 EC2 인스턴스에 역할을
연결합니다. 스냅샷을 삭제하려면 새 EC2 인스턴스에서 AWS CLI 를 사용하세요.

B. 스냅샷 삭제를 거부하는 IAM 정책을 생성합니다. 스토리지 관리자 사용자에게 정책을
연결합니다.

C. 스냅샷에 태그를 추가합니다. 태그가 있는 EBS 스냅샷에 대해 휴지통에 보관 규칙을
만듭니다.

D. 삭제를 방지하기 위해 EBS 스냅샷을 잠급니다.</div>

<details class="markdown-toggle">
  <summary><b>Answer</b></summary>
  <div markdown="1">
    <ul>
      <li>
        <span class="answer">D</span> <br/>
      </li>
    </ul>
    
-  EBS 스냅샷에 대한 삭제 방지를 위해 스냅샷 잠금 기능을 사용하면 실수로 인한 삭제를 방지할 수 있음. 이 방식은 스토리지 관리자 사용자의 관리 권한을 변경할 필요가 없고, 최소한의 관리 노력으로 규정 준수를 충족할 수 있음.

    - **A**는 IAM 역할을 생성하고 별도의 EC2 인스턴스에서 CLI를 사용하여 스냅샷을 삭제하게 하는 방식이지만, 삭제 방지와는 무관함.

    - **B**는 삭제를 거부하는 IAM 정책을 생성하는 것으로 권한을 변경하지 않아야 한다는 요구에 맞지 않음.

    - **C**는 스냅샷 삭제를 보류하는 기능이 아닌, 삭제 후 복원할 수 있는 휴지통 기능이라 실수 방지와 다름.

  </div>
</details>

---

---

**회사의 애플리케이션은 Network Load Balancer, Auto Scaling 그룹, Amazon EC2 인스턴스
및 Amazon VPC 에 배포된 데이터베이스를 사용합니다. 이 회사는 Amazon VPC 에서 거의
실시간으로 네트워크 인터페이스를 오가는 트래픽에 대한 정보를 캡처하려고 합니다.
회사는 분석을 위해 Amazon OpenSearch Service 에 정보를 보내려고 합니다.
어떤 솔루션이 이러한 요구 사항을 충족합니까?**

<div class="options">

A. Amazon CloudWatch Logs 에 로그 그룹을 생성합니다. 로그 데이터를 로그 그룹으로
보내도록 VPC 흐름 로그를 구성합니다. Amazon Kinesis Data Streams 를 사용하여 로그
그룹의 로그를 OpenSearch Service 로 스트리밍합니다.

B. Amazon CloudWatch Logs 에 로그 그룹을 생성합니다. 로그 데이터를 로그 그룹으로
보내도록 VPC 흐름 로그를 구성합니다. Amazon Kinesis Data Firehose 를 사용하여 로그
그룹의 로그를 OpenSearch Service 로 스트리밍합니다.

C. AWS CloudTrail 에서 추적을 생성합니다. 로그 데이터를 추적으로 보내도록 VPC 흐름
로그를 구성합니다. Amazon Kinesis Data Streams 를 사용하여 트레일의 로그를
OpenSearch Service 로 스트리밍합니다.

D. AWS CloudTrail 에서 추적을 생성합니다. 로그 데이터를 추적으로 보내도록 VPC 흐름
로그를 구성합니다. Amazon Kinesis Data Firehose 를 사용하여 트레일의 로그를
OpenSearch Service 로 스트리밍합니다.</div>

<details class="markdown-toggle">
  <summary><b>Answer</b></summary>
  <div markdown="1">
    <ul>
      <li>
        <span class="answer">B</span> <br/>
      </li>
    </ul>
    
- 이 솔루션은 VPC 네트워크 트래픽을 거의 실시간으로 캡처할 수 있도록 VPC 흐름 로그를 설정하고, CloudWatch Logs를 통해 데이터를 수집한 후 Kinesis Data Firehose를 이용해 OpenSearch Service로 스트리밍함. Firehose는 데이터 변환과 전송을 쉽게 해주며, OpenSearch에 실시간 로그 데이터를 보내기 위한 적절한 선택임.

    - **A**는 Kinesis Data Streams를 사용하지만, Data Firehose가 실시간 스트리밍 및 로그 전송을 위한 더 적합한 선택임. Data Streams는 실시간 스트리밍에는 유용하지만, Data Firehose만큼 OpenSearch에 직접 연결되는 전송 파이프라인을 제공하지 않음.
    - **C**와 **D**는 CloudTrail을 사용하므로 네트워크 트래픽에 대한 VPC 흐름 로그와는 다름. CloudTrail은 API 호출 이벤트 로깅에 중점을 두고 있음.

  </div>
</details>

---

---

**한 회사가 프로덕션 Amazon Elastic Kubernetes Service(Amazon EKS) 클러스터에서 실행될
애플리케이션을 개발하고 있습니다. EKS 클러스터에는 온디맨드 인스턴스로 프로비저닝되는
관리형 노드 그룹이 있습니다.
회사에는 개발 작업을 위한 전용 EKS 클러스터가 필요합니다. 회사는 애플리케이션의
복원력을 테스트하기 위해 개발 클러스터를 자주 사용하지 않습니다. EKS 클러스터는 모든
노드를 관리해야 합니다.
이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까?**

<div class="options">

A. 스팟 인스턴스만 포함하는 관리형 노드 그룹을 생성합니다.

B. 두 개의 관리형 노드 그룹을 생성합니다. 온디맨드 인스턴스로 하나의 노드 그룹을
프로비저닝합니다. 스팟 인스턴스로 두 번째 노드 그룹을 프로비저닝합니다.

C. 스팟 인스턴스를 사용하는 시작 구성이 있는 Auto Scaling 그룹을 생성합니다. EKS
클러스터에 노드를 추가하도록 사용자 데이터를 구성합니다.

D. 온디맨드 인스턴스만 포함하는 관리형 노드 그룹을 생성합니다.</div>

<details class="markdown-toggle">
  <summary><b>Answer</b></summary>
  <div markdown="1">
    <ul>
      <li>
        <span class="answer">A</span> <br/>
      </li>
    </ul>
    
- 스팟 인스턴스만 포함하는 관리형 노드 그룹을 생성하는 게 가장 비용 효율적임. 스팟 인스턴스는 온디맨드보다 저렴하고, 개발 클러스터처럼 자주 사용되지 않는 환경에 딱 맞음. EKS 관리형 노드 그룹을 사용하면 AWS가 자동으로 노드를 관리해서 편리하고, 스팟 인스턴스로 비용 절감 가능.

    - **B**. 두 개의 관리형 노드 그룹을 만들고 온디맨드와 스팟 인스턴스를 혼합하는 방법인데, 자주 사용되지 않는 개발 클러스터에선 스팟 인스턴스만 쓰는 게 더 효율적임.

    - **C**. 스팟 인스턴스를 사용하는 Auto Scaling 그룹을 만드는 방법은 관리형 노드 그룹을 사용하는 것보다 더 복잡함. 관리형 노드 그룹은 AWS가 자동으로 노드를 관리해줘서 더 간단하고 효율적임.

    - **D**. 온디맨드 인스턴스만 사용하는 방법은 비용이 더 많이 들음. 개발 클러스터에는 스팟 인스턴스를 사용하는 게 더 비용 효율적임.

  </div>
</details>

---

---

**회사는 민감한 데이터를 Amazon S3 에 저장합니다. 솔루션 설계자는 암호화 솔루션을
만들어야 합니다. 회사는 암호화해야 하는 모든 데이터에 대해 최소한의 노력으로 암호화
키를 생성, 순환 및 비활성화할 수 있는 사용자의 능력을 완전히 제어해야 합니다.
어떤 솔루션이 이러한 요구 사항을 충족합니까?**

<div class="options">

A. Amazon S3 관리형 암호화 키(SSE-S3)와 함께 기본 서버 측 암호화를 사용하여 민감한
데이터를 저장합니다.

B. AWS Key Management Service(AWS KMS)를 사용하여 고객 관리형 키를 생성합니다.
AWS KMS 키(SSE-KMS)로 서버 측 암호화를 사용하여 S3 객체를 암호화하려면 새 키를
사용합니다.

C. AWS Key Management Service(AWS KMS)를 사용하여 AWS 관리형 키를 생성합니다.
AWS KMS 키(SSE-KMS)로 서버 측 암호화를 사용하여 S3 객체를 암호화하려면 새 키를
사용합니다.

D. S3 객체를 Amazon EC2 인스턴스로 다운로드합니다. 고객 관리 키를 사용하여 객체를
암호화합니다. 암호화된 객체를 Amazon S3 에 다시 업로드합니다.</div>

<details class="markdown-toggle">
  <summary><b>Answer</b></summary>
  <div markdown="1">
    <ul>
      <li>
        <span class="answer">B</span> <br/>
      </li>
    </ul>
    
- AWS Key Management Service(AWS KMS)를 사용하여 고객 관리형 키를 생성하고, SSE-KMS로 S3 객체를 암호화하는 방법이 가장 적합함. 이 솔루션은 암호화 키의 생성, 순환, 비활성화 및 권한 관리에 대해 완전한 제어를 제공함. AWS KMS를 사용하면 암호화 키를 세밀하게 관리할 수 있고, S3에서 데이터 암호화를 할 때도 고객이 지정한 키를 사용할 수 있음.

    - **A**. SSE-S3는 S3에서 자동으로 관리하는 암호화 키를 사용하지만, 이 방식은 사용자가 암호화 키를 직접 관리하지 않기 때문에 암호화 키의 생성, 순환, 비활성화 등을 제어할 수 없음.
    - **C**. AWS KMS에서 제공하는 AWS 관리형 키는 AWS가 자동으로 관리하므로, 고객이 키의 순환이나 비활성화를 제어할 수 없음. 고객 관리형 키가 필요함.
    - **D**. 객체를 EC2로 다운로드하고 다시 암호화하여 S3에 업로드하는 방식은 불필요하게 복잡하며, 키 관리나 암호화 프로세스에 대해 더 많은 수동 작업을 요구함.

  </div>
</details>

---

---

**회사에서 온프레미스 가상 머신(VM)을 AWS 에 백업하려고 합니다. 회사의 백업 솔루션은
온프레미스 백업을 Amazon S3 버킷에 객체로 내보냅니다. S3 백업은 30 일 동안
보관되어야 하며 30 일 후에 자동으로 삭제되어야 합니다.
이러한 요구 사항을 충족하는 단계 조합은 무엇입니까? (3 개 선택)**

<div class="options">

A. S3 객체 잠금이 활성화된 S3 버킷을 생성합니다.

B. 객체 버전 관리가 활성화된 S3 버킷을 생성합니다.

C. 객체의 기본 보존 기간을 30 일로 구성합니다.

D. 30 일 동안 객체를 보호하도록 S3 수명 주기 정책을 구성합니다.

E. 30 일 후에 객체가 만료되도록 S3 수명 주기 정책을 구성합니다.

F. 30 일 보존 기간으로 개체에 태그를 지정하도록 백업 솔루션을 구성합니다.</div>

<details class="markdown-toggle">
  <summary><b>Answer</b></summary>
  <div markdown="1">
    <ul>
      <li>
        <span class="answer">A,C,E</span> <br/>
      </li>
    </ul>
    
- **A. S3 객체 잠금이 활성화된 S3 버킷을 생성합니다.**
    - S3 객체 잠금은 데이터 보존 및 무결성 요구 사항을 충족하는 데 유용합니다. 객체 잠금을 활성화하면 데이터가 삭제되지 않도록 보호할 수 있지만, 이는 자동 삭제와는 직접적인 관계가 없습니다. 잠금은 주로 법적 보존 요구 사항을 위해 사용되며, 이 경우에는 객체 삭제를 방지하기 위한 기능보다는 수명 주기 정책을 통한 자동 삭제가 필요함.
- **C. 객체의 기본 보존 기간을 30일로 구성합니다.**
    - 이 옵션은 S3 객체가 생성된 후 30일 동안 보관되도록 설정하는 것으로, 객체의 보존 기간을 설정하는 중요한 부분입니다. 기본 보존 기간을 30일로 설정하면, 객체가 해당 기간 동안 자동으로 삭제되도록 할 수 있습니다. 이 설정은 자동 삭제 요구 사항을 충족함.
- **E. 30일 후에 객체가 만료되도록 S3 수명 주기 정책을 구성합니다.**
    - S3 수명 주기 정책을 사용하여 객체의 만료를 설정할 수 있습니다. 이 경우, 객체가 30일 후에 자동으로 삭제되도록 수명 주기 정책을 구성함으로써 요구 사항을 충족할 수 있습니다. 객체의 만료 설정은 자동 삭제 기능을 제공하며, 30일 후 객체를 자동으로 삭제하는 데 적합함.
  </div>
</details>

---

<style>
  .markdown-toggle {
    background-color: #f7d0d0;
    border: 1px solid #ddd;
    border-radius: 8px;
    padding: 0.5rem;
    width: auto;
    max-width: 75px;
    margin-bottom: 1.5rem;
    transition: all 0.3s ease;
  }

  .markdown-toggle summary {
    font-weight: bold;
    cursor: pointer;
    font-size: 1rem;
    color: #333;
    transition: color 0.3s ease;
    width: fit-content;
    margin-right: 0;
  }

  .markdown-toggle summary:hover {
    color: #000;
  }

  .markdown-toggle[open] {
    background-color: #e6f7ff;
    width: auto;
    max-width: 700px;
  }

  .markdown-toggle[open] summary {
    color: #333;
  }

  .markdown-toggle div {
    margin-top: 1rem;
    color: #333;
    transition: opacity 0.3s ease, max-height 0.3s ease;
    font-size: 1rem;
    margin-right:50px
  }

  .markdown-toggle:not([open]) div {
    opacity: 0;
    max-height: 0;
    overflow: hidden;
  }

  .markdown-toggle[open] div {
    opacity: 1;
    max-height: none;
  }

  b {
    font-weight: bold;
  }

 .options {
    font-size: 1.1rem;
    line-height: 1.6;
    margin-top: 1rem;
    color: #333;
  }

  .answer {
    color: #d9534f;
    font-weight: bold;
  }
</style>

<script src="https://utteranc.es/client.js"
        repo="tjsgh1217/tjsgh1217.github.io"
        issue-term="pathname"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script>
